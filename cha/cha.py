import re
import time
import requests
import yaml
import base64
from typing import Dict, Optional, Tuple, List
from urllib.parse import unquote
from bs4 import BeautifulSoup
from pagermaid.enums import Message
from pagermaid.listener import listener
from pagermaid.utils import alias_command
from pagermaid.dependence import client as http_client

UNITS = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']
NODE_PATTERNS = [
    'vmess://', 'trojan://', 'ss://', 'ssr://',
    'vless://', 'hy2://', 'hysteria://', 'hy://'
]
REGION_RULES = [
    ('é¦™æ¸¯', ['é¦™æ¸¯', 'hong kong', 'hongkong', 'hk', 'ğŸ‡­ğŸ‡°']),
    ('å°æ¹¾', ['å°æ¹¾', 'taiwan', 'tw', 'ğŸ‡¹ğŸ‡¼']),
    ('æ—¥æœ¬', ['æ—¥æœ¬', 'japan', 'jp', 'ğŸ‡¯ğŸ‡µ']),
    ('æ–°åŠ å¡', ['æ–°åŠ å¡', 'singapore', 'sg', 'ğŸ‡¸ğŸ‡¬']),
    ('ç¾å›½', ['ç¾å›½', 'united states', 'us', 'usa', 'ğŸ‡ºğŸ‡¸']),
    ('éŸ©å›½', ['éŸ©å›½', 'korea', 'kr', 'ğŸ‡°ğŸ‡·']),
    ('å¾·å›½', ['å¾·å›½', 'germany', 'de', 'ğŸ‡©ğŸ‡ª']),
    ('è‹±å›½', ['è‹±å›½', 'united kingdom', 'uk', 'ğŸ‡¬ğŸ‡§'])
]

def format_size(size: int) -> str:
    """å°†å­—èŠ‚å¤§å°è½¬æ¢ä¸ºäººç±»å¯è¯»çš„æ ¼å¼"""
    def _format(integer: int, remainder: int, level: int) -> Tuple[int, int, int]:
        if integer >= 1024:
            remainder = integer % 1024
            integer //= 1024
            level += 1
            return _format(integer, remainder, level)
        return integer, remainder, level

    if size < 0:
        size = 0
    integer, remainder, level = _format(size, 0, 0)
    if level + 1 > len(UNITS):
        level = -1
    return f'{integer}.{remainder:>03d} {UNITS[level]}'

def format_time_remaining(seconds: int) -> str:
    """å°†ç§’æ•°è½¬æ¢ä¸ºå¤©å’Œå°æ—¶çš„æ ¼å¼"""
    days = int(seconds // 86400)
    hours = int((seconds % 86400) // 3600)
    return f"{str(days).zfill(2)}å¤©{str(hours).zfill(2)}å°æ—¶"

def get_filename_from_url(url: str) -> str:
    """ä»URLä¸­è·å–æœºåœºåç§°"""
    if "sub?target=" in url:
        pattern = r"url=([^&]*)"
        match = re.search(pattern, url)
        if match:
            return get_filename_from_url(unquote(match.group(1)))
            
    if "api/v1/client/subscribe?token" in url:
        url = f"{url}&flag=clash" if "&flag=clash" not in url else url
        try:
            response = requests.get(url)
            header = response.headers.get('Content-Disposition')
            if header:
                pattern = r"filename\*=UTF-8''(.+)"
                result = re.search(pattern, header)
                if result:
                    filename = unquote(result.group(1))
                    return filename.replace("%20", " ").replace("%2B", "+")
        except:
            return 'æœªçŸ¥'
            
    try:
        base_url = re.match(r'(https?://[^/]+)', url).group(1)
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        response = requests.get(f"{base_url}/auth/login", headers=headers, timeout=10)
        if response.status_code != 200:
            response = requests.get(base_url, headers=headers, timeout=1)
            
        soup = BeautifulSoup(response.content, 'html.parser')
        title = str(soup.title.string).replace('ç™»å½• â€” ', '')
        
        if "Attention Required! | Cloudflare" in title:
            return 'è¯¥åŸŸåä»…é™å›½å†…IPè®¿é—®'
        if "Access denied" in title or "404 Not Found" in title:
            return 'è¯¥åŸŸåéæœºåœºé¢æ¿åŸŸå'
        if "Just a moment" in title:
            return 'è¯¥åŸŸåå¼€å¯äº†5sç›¾'
        return title
    except:
        return 'æœªçŸ¥'

def get_node_info(url: str, headers: Dict) -> Optional[Dict]:
    """è·å–èŠ‚ç‚¹ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ•°é‡ã€ç±»å‹å’Œåœ°åŒºåˆ†å¸ƒ"""
    try:
        res = requests.get(url, headers=headers, timeout=5)
        if res.status_code != 200:
            return None
            
        # å°è¯•è§£æä¸ºYAMLæ ¼å¼
        try:
            config = yaml.safe_load(res.text)
            if config and 'proxies' in config:
                type_count = {}
                regions = {}
                
                for proxy in config['proxies']:
                    # ç»Ÿè®¡ç±»å‹
                    proxy_type = proxy.get('type', '').lower()
                    type_count[proxy_type] = type_count.get(proxy_type, 0) + 1
                    
                    # è§£æåœ°åŒºä¿¡æ¯
                    name = proxy.get('name', '').lower()
                    for region_name, keywords in REGION_RULES:
                        if any(keyword in name for keyword in keywords):
                            regions[region_name] = regions.get(region_name, 0) + 1
                            break
                
                return {
                    'node_count': len(config['proxies']),
                    'type_count': {k: v for k, v in type_count.items() if v > 0},
                    'regions': {k: v for k, v in regions.items() if v > 0}
                }
        except yaml.YAMLError:
            pass
            
        # å¦‚æœä¸æ˜¯YAMLæ ¼å¼ï¼Œå°è¯•base64è§£ç 
        try:
            decoded_content = base64.b64decode(res.text).decode('utf-8')
            type_count = {pattern.replace('://', ''): 0 for pattern in NODE_PATTERNS}
            regions = {}
            node_count = 0
            
            for line in decoded_content.splitlines():
                if not line.strip():
                    continue
                    
                # æ£€æµ‹èŠ‚ç‚¹ç±»å‹
                for pattern in NODE_PATTERNS:
                    if line.startswith(pattern):
                        type_count[pattern.replace('://', '')] += 1
                        node_count += 1
                        break
                        
                # è§£æåœ°åŒºä¿¡æ¯
                line_lower = line.lower()
                for region_name, keywords in REGION_RULES:
                    if any(keyword in line_lower for keyword in keywords):
                        regions[region_name] = regions.get(region_name, 0) + 1
                        break
                        
            return {
                'node_count': node_count,
                'type_count': {k: v for k, v in type_count.items() if v > 0},
                'regions': {k: v for k, v in regions.items() if v > 0}
            }
        except:
            return None
    except:
        return None

@listener(is_plugin=True, outgoing=True, command=alias_command("cha"),
          description='è¯†åˆ«è®¢é˜…é“¾æ¥å¹¶è·å–ä¿¡æ¯\nä½¿ç”¨æ–¹æ³•ï¼šä½¿ç”¨è¯¥å‘½ä»¤å‘é€æˆ–å›å¤ä¸€æ®µå¸¦æœ‰ä¸€æ¡æˆ–å¤šæ¡è®¢é˜…é“¾æ¥çš„æ–‡æœ¬',
          parameters='<url>')
async def subinfo(_, msg: Message):
    """è®¢é˜…ä¿¡æ¯æŸ¥è¯¢ä¸»å‡½æ•°"""
    headers = {'User-Agent': 'ClashMeta'}
    
    try:
        message_raw = msg.reply_to_message and (msg.reply_to_message.caption or msg.reply_to_message.text) or (msg.caption or msg.text)
        url_list = re.findall(r"https?://[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]", message_raw)
        
        final_output = []
        for url in url_list:
            try:
                res = await http_client.get(url, headers=headers, timeout=5)
                while res.status_code in (301, 302):
                    url = res.headers['location']
                    res = await http_client.get(url, headers=headers, timeout=5)
                    
                if res.status_code != 200:
                    final_output.append('æ— æ³•è®¿é—®')
                    continue
                    
                try:
                    info = res.headers['subscription-userinfo']
                    info_num = [int(x) for x in re.findall(r'\d+', info)]
                    time_now = int(time.time())
                    
                    # è·å–èŠ‚ç‚¹ä¿¡æ¯
                    node_info = get_node_info(url, headers)
                    node_count = node_info['node_count'] if node_info else 'æœªçŸ¥'
                    
                    # ç”Ÿæˆè¾“å‡ºä¿¡æ¯
                    output_lines = [
                        f'è®¢é˜…é“¾æ¥ï¼š`{url}`',
                        f'æœºåœºåï¼š`{get_filename_from_url(url)}`',
                        f'å·²ç”¨ä¸Šè¡Œï¼š`{format_size(info_num[0])}`',
                        f'å·²ç”¨ä¸‹è¡Œï¼š`{format_size(info_num[1])}`',
                        f'å‰©ä½™ï¼š`{format_size(info_num[2] - info_num[1] - info_num[0])}`',
                        f'æ€»å…±ï¼š`{format_size(info_num[2])}`',
                        f'ä½¿ç”¨æ¯”ä¾‹ï¼š`{round((info_num[0] + info_num[1]) / info_num[2] * 100, 2)}%`',
                        f'èŠ‚ç‚¹æ•°é‡ï¼š`{node_count}`'
                    ]
                    
                    if node_info:
                        if node_info['type_count']:
                            type_str = ', '.join(f'{k}:{v}' for k, v in node_info['type_count'].items())
                            output_lines.append(f'èŠ‚ç‚¹ç±»å‹ï¼š`{type_str}`')
                        if node_info['regions']:
                            region_str = ', '.join(f'{k}:{v}' for k, v in node_info['regions'].items())
                            output_lines.append(f'èŠ‚ç‚¹åœ°åŒºï¼š`{region_str}`')
                    
                    # æ·»åŠ è¿‡æœŸæ—¶é—´ä¿¡æ¯
                    if len(info_num) >= 4:
                        expire_time = time.strftime("%Y-%m-%d", time.localtime(info_num[3] + 28800))
                        if time_now <= info_num[3]:
                            remaining = format_time_remaining(info_num[3] - time_now)
                            output_lines.append(f'æ­¤è®¢é˜…å°†äº`{expire_time}`è¿‡æœŸï¼Œå‰©ä½™`{remaining}`')
                        else:
                            output_lines.append(f'æ­¤è®¢é˜…å·²äº`{expire_time}`è¿‡æœŸï¼')
                    else:
                        output_lines.append('åˆ°æœŸæ—¶é—´ï¼š`æœªçŸ¥`')
                        
                    final_output.append('\n'.join(output_lines))
                except KeyError:
                    final_output.append(f'è®¢é˜…é“¾æ¥ï¼š`{url}`\næœºåœºåï¼š`{get_filename_from_url(url)}`\næ— æµé‡ä¿¡æ¯')
            except:
                final_output.append('è¿æ¥é”™è¯¯')
                
        await msg.edit('\n\n'.join(final_output))
    except Exception as e:
        await msg.edit(f'å‚æ•°é”™è¯¯: {str(e)}')
